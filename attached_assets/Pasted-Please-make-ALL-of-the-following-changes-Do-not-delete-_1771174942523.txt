Please make ALL of the following changes. Do not delete or modify any existing code unless I specifically say "replace."
STEP 1: Add AI Screener Method to Market Data Service
In data/market_data_service.py, add this method to the MarketDataService class:
python    async def run_ai_screener(self, filters: dict) -> dict:
        """
        AI-powered custom screener. Takes parsed filter criteria and
        builds Finviz screen URL, runs it, then enriches results with
        StockAnalysis fundamentals.
        
        filters dict can contain:
        - market_cap_min, market_cap_max (in billions, e.g. 0.05, 2)
        - revenue_growth_min (e.g. 30 for 30%+)
        - eps_growth_min
        - pe_max, pe_min
        - ps_max
        - price_min, price_max
        - rsi_max, rsi_min
        - above_sma200 (bool)
        - above_sma50 (bool)
        - below_sma200 (bool)
        - below_sma50 (bool)
        - insider_buying (bool)
        - analyst_upgrades (bool)
        - unusual_volume (bool)
        - relative_volume_min (e.g. 1.5)
        - avg_volume_min (e.g. 200 for 200K)
        - sector (string)
        - industry (string)
        - positive_margin (bool)
        - dividend_yield_min
        - short_float_min, short_float_max
        - debt_equity_max
        - current_ratio_min
        - custom_finviz_params (string - raw Finviz filter if needed)
        """
        import asyncio
        from data.scoring_engine import score_for_trades

        # ── Build Finviz filter string from parsed criteria ──
        f_parts = []

        # Market cap
        cap_map_min = {0: "", 0.05: "cap_microover", 0.3: "cap_smallover", 2: "cap_midover", 10: "cap_largeover", 200: "cap_megaover"}
        cap_map_max = {0.05: "cap_microunder", 0.3: "cap_smallunder", 2: "cap_midunder", 10: "cap_largeunder", 200: "cap_megaunder"}

        mc_min = filters.get("market_cap_min")
        mc_max = filters.get("market_cap_max")
        if mc_min is not None:
            # Find closest Finviz bracket
            if mc_min >= 200: f_parts.append("cap_megaover")
            elif mc_min >= 10: f_parts.append("cap_largeover")
            elif mc_min >= 2: f_parts.append("cap_midover")
            elif mc_min >= 0.3: f_parts.append("cap_smallover")
            elif mc_min >= 0.05: f_parts.append("cap_microover")
        if mc_max is not None:
            if mc_max <= 0.3: f_parts.append("cap_smallunder")
            elif mc_max <= 2: f_parts.append("cap_midunder")
            elif mc_max <= 10: f_parts.append("cap_largeunder")
            elif mc_max <= 200: f_parts.append("cap_megaunder")

        # Revenue growth
        rg = filters.get("revenue_growth_min")
        if rg is not None:
            if rg >= 30: f_parts.append("fa_salesqoq_o30")
            elif rg >= 25: f_parts.append("fa_salesqoq_o25")
            elif rg >= 20: f_parts.append("fa_salesqoq_o20")
            elif rg >= 15: f_parts.append("fa_salesqoq_o15")
            elif rg >= 10: f_parts.append("fa_salesqoq_o10")
            elif rg >= 5: f_parts.append("fa_salesqoq_o5")

        # EPS growth
        eg = filters.get("eps_growth_min")
        if eg is not None:
            if eg >= 30: f_parts.append("fa_epsqoq_o30")
            elif eg >= 25: f_parts.append("fa_epsqoq_o25")
            elif eg >= 20: f_parts.append("fa_epsqoq_o20")
            elif eg >= 15: f_parts.append("fa_epsqoq_o15")
            elif eg >= 10: f_parts.append("fa_epsqoq_o10")
            elif eg >= 5: f_parts.append("fa_epsqoq_o5")

        # P/E
        pe_max = filters.get("pe_max")
        if pe_max is not None:
            if pe_max <= 5: f_parts.append("fa_pe_u5")
            elif pe_max <= 10: f_parts.append("fa_pe_u10")
            elif pe_max <= 15: f_parts.append("fa_pe_u15")
            elif pe_max <= 20: f_parts.append("fa_pe_u20")
            elif pe_max <= 30: f_parts.append("fa_pe_u30")
            elif pe_max <= 40: f_parts.append("fa_pe_u40")
            elif pe_max <= 50: f_parts.append("fa_pe_u50")

        # P/S
        ps_max = filters.get("ps_max")
        if ps_max is not None:
            if ps_max <= 1: f_parts.append("fa_ps_u1")
            elif ps_max <= 2: f_parts.append("fa_ps_u2")
            elif ps_max <= 3: f_parts.append("fa_ps_u3")
            elif ps_max <= 5: f_parts.append("fa_ps_u5")

        # Price
        p_min = filters.get("price_min")
        if p_min is not None:
            if p_min >= 50: f_parts.append("sh_price_o50")
            elif p_min >= 20: f_parts.append("sh_price_o20")
            elif p_min >= 10: f_parts.append("sh_price_o10")
            elif p_min >= 5: f_parts.append("sh_price_o5")

        p_max = filters.get("price_max")
        if p_max is not None:
            if p_max <= 5: f_parts.append("sh_price_u5")
            elif p_max <= 10: f_parts.append("sh_price_u10")
            elif p_max <= 20: f_parts.append("sh_price_u20")
            elif p_max <= 50: f_parts.append("sh_price_u50")

        # RSI
        rsi_max = filters.get("rsi_max")
        if rsi_max is not None:
            if rsi_max <= 30: f_parts.append("ta_rsi_os30")
            elif rsi_max <= 40: f_parts.append("ta_rsi_os40")
            elif rsi_max <= 50: f_parts.append("ta_rsi_os50")
            elif rsi_max <= 60: f_parts.append("ta_rsi_os60")

        rsi_min = filters.get("rsi_min")
        if rsi_min is not None:
            if rsi_min >= 70: f_parts.append("ta_rsi_ob70")
            elif rsi_min >= 60: f_parts.append("ta_rsi_ob60")
            elif rsi_min >= 50: f_parts.append("ta_rsi_ob50")

        # SMA positions
        if filters.get("above_sma200"): f_parts.append("ta_sma200_pa")
        if filters.get("above_sma50"): f_parts.append("ta_sma50_pa")
        if filters.get("below_sma200"): f_parts.append("ta_sma200_pb")
        if filters.get("below_sma50"): f_parts.append("ta_sma50_pb")

        # Insider buying
        if filters.get("insider_buying"): f_parts.append("it_latestbuys")

        # Analyst upgrades
        if filters.get("analyst_upgrades"): f_parts.append("ta_change_u")

        # Volume
        if filters.get("unusual_volume"): f_parts.append("sh_relvol_o1.5")
        rv = filters.get("relative_volume_min")
        if rv is not None:
            if rv >= 3: f_parts.append("sh_relvol_o3")
            elif rv >= 2: f_parts.append("sh_relvol_o2")
            elif rv >= 1.5: f_parts.append("sh_relvol_o1.5")

        av = filters.get("avg_volume_min")
        if av is not None:
            if av >= 1000: f_parts.append("sh_avgvol_o1000")
            elif av >= 500: f_parts.append("sh_avgvol_o500")
            elif av >= 400: f_parts.append("sh_avgvol_o400")
            elif av >= 300: f_parts.append("sh_avgvol_o300")
            elif av >= 200: f_parts.append("sh_avgvol_o200")
            elif av >= 100: f_parts.append("sh_avgvol_o100")
        else:
            f_parts.append("sh_avgvol_o200")  # Default minimum

        # Positive margin
        if filters.get("positive_margin"): f_parts.append("fa_opermargin_pos")

        # Debt/equity
        de_max = filters.get("debt_equity_max")
        if de_max is not None:
            if de_max <= 0.5: f_parts.append("fa_debteq_u0.5")
            elif de_max <= 1: f_parts.append("fa_debteq_u1")

        # Short float
        sf_min = filters.get("short_float_min")
        if sf_min is not None:
            if sf_min >= 20: f_parts.append("sh_short_o20")
            elif sf_min >= 15: f_parts.append("sh_short_o15")
            elif sf_min >= 10: f_parts.append("sh_short_o10")
            elif sf_min >= 5: f_parts.append("sh_short_o5")

        # Sector
        sector = filters.get("sector")
        if sector:
            sector_map = {
                "technology": "sec_technology",
                "healthcare": "sec_healthcare",
                "financial": "sec_financial",
                "energy": "sec_energy",
                "industrials": "sec_industrials",
                "consumer cyclical": "sec_consumercyclical",
                "consumer defensive": "sec_consumerdefensive",
                "basic materials": "sec_basicmaterials",
                "real estate": "sec_realestate",
                "utilities": "sec_utilities",
                "communication services": "sec_communicationservices",
            }
            sec_code = sector_map.get(sector.lower(), "")
            if sec_code:
                f_parts.append(sec_code)

        # Custom raw params
        custom = filters.get("custom_finviz_params")
        if custom:
            f_parts.append(custom)

        # Build final Finviz URL
        filter_str = ",".join(f_parts) if f_parts else "sh_avgvol_o200"
        screen_url = f"v=111&f={filter_str}&ft=4&o=-sh_relvol"

        print(f"[AI Screener] Finviz filter: {screen_url}")
        print(f"[AI Screener] Parsed filters: {filters}")

        # ── Run the screen ──
        screener_results = await self.finviz._custom_screen(screen_url)
        if isinstance(screener_results, Exception) or not screener_results:
            return {
                "filters_applied": filters,
                "finviz_url": screen_url,
                "total_results": 0,
                "results": [],
                "error": "No stocks matched your criteria. Try loosening some filters.",
            }

        print(f"[AI Screener] Found {len(screener_results)} matches")

        # ── Enrich top results with StockAnalysis ──
        tickers_to_enrich = screener_results[:30]

        async def enrich_ticker(item):
            ticker = item.get("ticker", "")
            if not ticker:
                return item
            try:
                overview, analyst = await asyncio.gather(
                    self.stockanalysis.get_overview(ticker),
                    self.stockanalysis.get_analyst_ratings(ticker),
                    return_exceptions=True,
                )
                item["sa_overview"] = overview if not isinstance(overview, Exception) else {}
                item["sa_analyst"] = analyst if not isinstance(analyst, Exception) else {}
            except:
                item["sa_overview"] = {}
                item["sa_analyst"] = {}
            return item

        enriched = await asyncio.gather(
            *[enrich_ticker(item) for item in tickers_to_enrich],
            return_exceptions=True,
        )

        # Clean results
        clean_results = []
        for r in enriched:
            if isinstance(r, Exception):
                continue
            if isinstance(r, dict):
                clean_results.append(r)

        return {
            "filters_applied": filters,
            "finviz_url": screen_url,
            "total_results": len(screener_results),
            "showing": len(clean_results),
            "results": clean_results,
        }
STEP 2: Add AI Screener Route in Agent
In agent/claude_agent.py, add to _gather_data:
python        elif category == "ai_screener":
            return await self.data.run_ai_screener(self._parse_screener_filters(prompt))
Also add this helper method to the agent class:
python    def _parse_screener_filters(self, prompt: str) -> dict:
        """
        Pass the raw prompt to Claude to extract structured filter criteria.
        For now, return the raw prompt as a 'natural_language' field —
        the system prompt will instruct Claude to parse it and call
        the screener with structured filters.
        """
        return {"natural_language": prompt}
IMPORTANT: Also update _gather_data for ai_screener to handle natural language parsing.
Replace the ai_screener elif block with this smarter version:
python        elif category == "ai_screener":
            # Extract filters from natural language prompt
            filters = self._extract_screener_filters(prompt)
            return await self.data.run_ai_screener(filters)
Add this method to the agent class:
python    def _extract_screener_filters(self, prompt: str) -> dict:
        """
        Parse natural language screener request into structured filters.
        Uses keyword matching for common criteria.
        """
        import re
        filters = {}
        p = prompt.lower()

        # Market cap
        cap_match = re.search(r'(?:market\s*cap|mcap).*?(?:under|below|<|max)\s*\$?(\d+\.?\d*)\s*([bmtBMT])', p)
        if cap_match:
            val = float(cap_match.group(1))
            unit = cap_match.group(2).lower()
            if unit == 'm': val /= 1000
            elif unit == 't': val *= 1000
            filters["market_cap_max"] = val

        cap_match2 = re.search(r'(?:market\s*cap|mcap).*?(?:over|above|>|min|at least)\s*\$?(\d+\.?\d*)\s*([bmtBMT])', p)
        if cap_match2:
            val = float(cap_match2.group(1))
            unit = cap_match2.group(2).lower()
            if unit == 'm': val /= 1000
            elif unit == 't': val *= 1000
            filters["market_cap_min"] = val

        # Small cap shorthand
        if "small cap" in p and "market_cap_max" not in filters:
            filters["market_cap_max"] = 2
        if "micro cap" in p and "market_cap_max" not in filters:
            filters["market_cap_max"] = 0.3
        if "mid cap" in p:
            filters.setdefault("market_cap_min", 2)
            filters.setdefault("market_cap_max", 10)
        if "large cap" in p:
            filters.setdefault("market_cap_min", 10)

        # Revenue growth
        rev_match = re.search(r'(?:revenue|sales)\s*(?:growth)?\s*(?:>|over|above|at least|min)?\s*(\d+)\s*%', p)
        if rev_match:
            filters["revenue_growth_min"] = int(rev_match.group(1))
        elif "revenue growth" in p or "sales growth" in p:
            filters["revenue_growth_min"] = 10  # Default

        # EPS growth
        eps_match = re.search(r'(?:eps|earnings)\s*(?:growth)?\s*(?:>|over|above)?\s*(\d+)\s*%', p)
        if eps_match:
            filters["eps_growth_min"] = int(eps_match.group(1))

        # P/E
        pe_match = re.search(r'(?:p/?e|pe ratio)\s*(?:<|under|below|max)?\s*(\d+)', p)
        if pe_match:
            filters["pe_max"] = int(pe_match.group(1))

        # P/S
        ps_match = re.search(r'(?:p/?s|price.to.sales)\s*(?:<|under|below)?\s*(\d+)', p)
        if ps_match:
            filters["ps_max"] = int(ps_match.group(1))

        # RSI
        rsi_low = re.search(r'rsi\s*(?:<|under|below)\s*(\d+)', p)
        if rsi_low:
            filters["rsi_max"] = int(rsi_low.group(1))
        rsi_high = re.search(r'rsi\s*(?:>|over|above)\s*(\d+)', p)
        if rsi_high:
            filters["rsi_min"] = int(rsi_high.group(1))
        if "oversold" in p and "rsi_max" not in filters:
            filters["rsi_max"] = 30
        if "overbought" in p and "rsi_min" not in filters:
            filters["rsi_min"] = 70

        # SMA
        if "above 200" in p or "above sma200" in p or "above 200 sma" in p:
            filters["above_sma200"] = True
        if "above 50" in p or "above sma50" in p or "above 50 sma" in p:
            filters["above_sma50"] = True
        if "below 200" in p or "below sma200" in p:
            filters["below_sma200"] = True
        if "below 50" in p or "below sma50" in p:
            filters["below_sma50"] = True
        if "stage 2" in p:
            filters["above_sma200"] = True
            filters["above_sma50"] = True

        # Insider buying
        if "insider buy" in p or "insider purchas" in p:
            filters["insider_buying"] = True

        # Volume
        if "unusual volume" in p or "volume spike" in p:
            filters["unusual_volume"] = True
        rv_match = re.search(r'(?:relative|rel)\s*(?:volume|vol)\s*(?:>|over|above)?\s*(\d+\.?\d*)', p)
        if rv_match:
            filters["relative_volume_min"] = float(rv_match.group(1))

        # Profitability
        if "profitable" in p or "positive margin" in p or "positive ebitda" in p:
            filters["positive_margin"] = True

        # Debt
        de_match = re.search(r'(?:debt.to.equity|d/?e)\s*(?:<|under|below)\s*(\d+\.?\d*)', p)
        if de_match:
            filters["debt_equity_max"] = float(de_match.group(1))
        if "low debt" in p and "debt_equity_max" not in filters:
            filters["debt_equity_max"] = 0.5

        # Short float
        sf_match = re.search(r'short\s*(?:float|interest)\s*(?:>|over|above)\s*(\d+)', p)
        if sf_match:
            filters["short_float_min"] = int(sf_match.group(1))

        # Sector
        sector_keywords = {
            "tech": "technology", "healthcare": "healthcare", "health care": "healthcare",
            "financial": "financial", "bank": "financial", "energy": "energy",
            "industrial": "industrials", "consumer": "consumer cyclical",
            "real estate": "real estate", "utilities": "utilities", "materials": "basic materials",
        }
        for kw, sec in sector_keywords.items():
            if kw in p:
                filters["sector"] = sec
                break

        # Dividend
        div_match = re.search(r'dividend\s*(?:yield)?\s*(?:>|over|above|at least)\s*(\d+\.?\d*)', p)
        if div_match:
            filters["dividend_yield_min"] = float(div_match.group(1))

        print(f"[AI Screener] Extracted filters from prompt: {filters}")
        return filters
```

### STEP 3: Add AI Screener to Classifier

**In `agent/prompts.py`, in `QUERY_CLASSIFIER_PROMPT`, add:**
```
- "ai_screener": User wants to screen/scan/filter for stocks matching specific custom criteria. They mention specific technical or fundamental requirements like "find stocks with revenue growth >30%", "screen for oversold stocks with insider buying", "show me small caps with low P/E and high growth", or any request that includes multiple specific quantitative filters. This is NOT for general questions like "best trades" — it's for custom screening with user-defined parameters.
```

### STEP 4: Add AI Screener Display Format to System Prompt

**In `agent/prompts.py`, add this format:**
```
### FORMAT: "screener" — AI Custom Stock Screener Results
Use when: user asks to screen/scan/filter for stocks matching specific criteria.

You receive the results of a custom Finviz screen enriched with StockAnalysis data.
Your job is to present the results in a clean, sortable screener table format AND
provide analysis of the best opportunities in the results.
```json
{
  "display_type": "screener",
  "query_interpretation": "You asked for: small caps under $2B with revenue growth >30%, positive margins, RSI under 40, and insider buying",
  "filters_applied": {
    "market_cap_max": "$2B",
    "revenue_growth_min": "30%+",
    "positive_margin": true,
    "rsi_max": 40,
    "insider_buying": true
  },
  "total_matches": 12,
  "results": [
    {
      "ticker": "ACME",
      "company": "Acme Corp",
      "price": "$45.20",
      "change_pct": "+2.1%",
      "market_cap": "$1.2B",
      "pe_ratio": "18.5",
      "ps_ratio": "3.2",
      "revenue_growth": "+42% YoY",
      "eps_growth": "+35% YoY",
      "operating_margin": "18.5%",
      "profit_margin": "12.3%",
      "rsi": 35,
      "sma50": "Above",
      "sma200": "Above",
      "rel_volume": "1.8x",
      "avg_volume": "850K",
      "short_float": "4.2%",
      "analyst_rating": "Buy",
      "price_target": "$58.00",
      "upside": "+28%",
      "insider_activity": "3 buys last 30 days",
      "highlight": true,
      "note": "Best in screen — highest revenue growth with lowest RSI. Insider cluster buy pattern."
    }
  ],
  "top_picks": [
    {
      "ticker": "ACME",
      "why": "Strongest combination: 42% revenue growth, insiders buying aggressively, RSI 35 (oversold), 28% analyst upside. The fundamentals are accelerating while the stock is pulled back — textbook setup.",
      "trade_plan": {
        "entry": "$44-46",
        "stop": "$39",
        "target": "$58",
        "risk_reward": "1:2.3"
      }
    }
  ],
  "observations": "12 stocks matched your criteria. The healthcare sector dominates (7 of 12) — this aligns with our Stage 2 sector data showing healthcare in strong uptrend. 3 stocks have insider buying clusters which is the highest conviction signal."
}
```

RULES FOR SCREENER FORMAT:
- ALWAYS start with query_interpretation — restate what the user asked for in plain English
- Show filters_applied so the user can verify their criteria was understood correctly
- Present ALL results in a table-friendly format with consistent fields
- Every result must include: ticker, company, price, change, market_cap, and whatever metrics are relevant to the user's query
- Mark the best 1-3 results with "highlight": true and explain WHY in the note field
- Include top_picks section with analysis and trade plans for the highest conviction matches
- Include observations about patterns (sector clustering, common themes, etc.)
- If no results match, suggest which filter to loosen: "No matches found. The RSI <30 filter is very restrictive — try RSI <40."
- Include StockAnalysis data fields wherever available: revenue_growth, margins, analyst ratings, price targets
- If the user's criteria was vague, note what assumptions you made
STEP 5: Verify no conflicts
Make sure the ai_screener category doesn't conflict with other categories in the classifier. The key distinction is: ai_screener is for CUSTOM filter criteria specified by the user, not for general "best trades" or "what's trending" questions.
Re-deploy the backend.