PROMPT 1 — BACKEND ReplPlease make ALL of the following changes. Do not delete or modify any existing code unless I specifically say "replace."PART 1: Add Morning Briefing Data MethodIn data/market_data_service.py, add this method to the class:python    async def get_morning_briefing(self) -> dict:
        """
        Combined intelligence briefing pulling the top signal from every data source.
        Designed to give a full market snapshot + top actionable moves in one call.

        Runs ALL major scans in parallel, takes the #1 result from each,
        and packages everything for Claude to synthesize into a briefing.
        """
        import asyncio
        from data.scoring_engine import score_for_trades, score_for_investments, score_for_squeeze

        # ── Run all data feeds in parallel ──
        (
            # Market structure
            movers,
            fear_greed,
            fred_macro,
            # Screeners (cast wide net)
            stage2_breakouts,
            volume_breakouts,
            macd_crossovers,
            unusual_volume,
            new_highs,
            high_short,
            insider_buying,
            revenue_leaders,
            rsi_recovery,
            accumulation,
            # Social
            trending,
            # News
            market_news,
            upcoming_earnings,
        ) = await asyncio.gather(
            asyncio.to_thread(self.polygon.get_market_movers),
            self.fear_greed.get_fear_greed_index(),
            asyncio.to_thread(self.fred.get_quick_macro),
            self.finviz.get_stage2_breakouts(),
            self.finviz.get_volume_breakouts(),
            self.finviz.get_macd_crossovers(),
            self.finviz.get_unusual_volume(),
            self.finviz.get_new_highs(),
            self.finviz.get_high_short_float(),
            self.finviz.get_insider_buying(),
            self.finviz.get_revenue_growth_leaders(),
            self.finviz.get_rsi_recovery(),
            self.finviz.get_accumulation_stocks(),
            self.stocktwits.get_trending(),
            asyncio.to_thread(lambda: self.polygon.get_news(limit=10)),
            asyncio.to_thread(self.finnhub.get_upcoming_earnings),
            return_exceptions=True,
        )

        # Safe unwrap
        def safe(val, default=None):
            if default is None:
                default = []
            return val if not isinstance(val, Exception) else default

        movers = safe(movers, {})
        fear_greed = safe(fear_greed, {})
        fred_macro = safe(fred_macro, {})
        stage2_breakouts = safe(stage2_breakouts)
        volume_breakouts = safe(volume_breakouts)
        macd_crossovers = safe(macd_crossovers)
        unusual_volume = safe(unusual_volume)
        new_highs = safe(new_highs)
        high_short = safe(high_short)
        insider_buying = safe(insider_buying)
        revenue_leaders = safe(revenue_leaders)
        rsi_recovery = safe(rsi_recovery)
        accumulation = safe(accumulation)
        trending = safe(trending)
        market_news = safe(market_news)
        upcoming_earnings = safe(upcoming_earnings)

        # ── FMP macro data if available ──
        fmp_data = {}
        if self.fmp:
            try:
                dxy, commodities, treasuries, sector_perf, indices = await asyncio.gather(
                    self.fmp.get_dxy(),
                    self.fmp.get_key_commodities(),
                    self.fmp.get_treasury_rates(),
                    self.fmp.get_sector_performance(),
                    self.fmp.get_market_indices(),
                    return_exceptions=True,
                )
                fmp_data = {
                    "dxy": dxy if not isinstance(dxy, Exception) else {},
                    "commodities": commodities if not isinstance(commodities, Exception) else {},
                    "treasury_yields": treasuries if not isinstance(treasuries, Exception) else {},
                    "sector_performance": sector_perf if not isinstance(sector_perf, Exception) else [],
                    "indices": indices if not isinstance(indices, Exception) else {},
                }
            except:
                pass

        # ── Deduplicate all tickers across all screeners ──
        all_tickers = set()
        screener_sources = {}  # Track which screeners each ticker appeared in

        source_map = {
            "stage2_breakout": stage2_breakouts,
            "volume_breakout": volume_breakouts,
            "macd_crossover": macd_crossovers,
            "unusual_volume": unusual_volume,
            "new_high": new_highs,
            "high_short_float": high_short,
            "insider_buying": insider_buying,
            "revenue_growth": revenue_leaders,
            "rsi_recovery": rsi_recovery,
            "accumulation": accumulation,
        }

        for source_name, source_list in source_map.items():
            if isinstance(source_list, list):
                for item in source_list:
                    if isinstance(item, dict) and item.get("ticker"):
                        t = item["ticker"].upper().strip()
                        if len(t) <= 5 and t.isalpha():
                            all_tickers.add(t)
                            if t not in screener_sources:
                                screener_sources[t] = []
                            screener_sources[t].append(source_name)

        # Add trending tickers
        for t in (trending or []):
            if isinstance(t, dict) and t.get("ticker"):
                ticker = t["ticker"].upper().strip()
                all_tickers.add(ticker)
                if ticker not in screener_sources:
                    screener_sources[ticker] = []
                screener_sources[ticker].append("social_trending")

        # Add top movers
        for g in (movers.get("gainers") or []):
            if g.get("ticker"):
                ticker = g["ticker"].upper().strip()
                all_tickers.add(ticker)
                if ticker not in screener_sources:
                    screener_sources[ticker] = []
                screener_sources[ticker].append("top_gainer")

        print(f"[Briefing] {len(all_tickers)} unique tickers across all sources")

        # ── Multi-signal tickers (appeared in 2+ screeners) = highest priority ──
        multi_signal = {t: sources for t, sources in screener_sources.items() if len(sources) >= 2}
        single_signal = {t: sources for t, sources in screener_sources.items() if len(sources) == 1}

        print(f"[Briefing] {len(multi_signal)} multi-signal tickers: {list(multi_signal.keys())[:10]}")

        # ── Enrich top candidates ──
        # Prioritize multi-signal tickers, then fill with single-signal
        priority_tickers = list(multi_signal.keys())[:15]
        remaining_slots = 20 - len(priority_tickers)
        if remaining_slots > 0:
            filler = [t for t in single_signal.keys() if t not in priority_tickers][:remaining_slots]
            priority_tickers.extend(filler)

        async def enrich_briefing(ticker):
            try:
                snapshot = self.polygon.get_snapshot(ticker)
                technicals = self.polygon.get_technicals(ticker)
                details = self.polygon.get_ticker_details(ticker)

                st_result, overview = await asyncio.gather(
                    self.stocktwits.get_sentiment(ticker),
                    self.stockanalysis.get_overview(ticker),
                    return_exceptions=True,
                )

                return {
                    "snapshot": snapshot,
                    "technicals": technicals,
                    "details": details,
                    "sentiment": st_result if not isinstance(st_result, Exception) else {},
                    "overview": overview if not isinstance(overview, Exception) else {},
                }
            except Exception as e:
                return {"error": str(e)}

        enrichment_results = await asyncio.gather(
            *[enrich_briefing(t) for t in priority_tickers],
            return_exceptions=True,
        )

        enriched = {}
        for ticker, result in zip(priority_tickers, enrichment_results):
            if not isinstance(result, Exception) and isinstance(result, dict) and "error" not in result:
                # Score it
                trade_score = score_for_trades(result)
                invest_score = score_for_investments(result)
                result["trade_score"] = trade_score
                result["invest_score"] = invest_score
                result["signal_count"] = len(screener_sources.get(ticker, []))
                result["signal_sources"] = screener_sources.get(ticker, [])
                enriched[ticker] = result

        # Sort by signal count first, then by trade score
        ranked = sorted(
            enriched.items(),
            key=lambda x: (x[1].get("signal_count", 0), x[1].get("trade_score", 0)),
            reverse=True,
        )

        return {
            "total_tickers_detected": len(all_tickers),
            "multi_signal_tickers": {t: sources for t, sources in list(multi_signal.items())[:10]},
            "ranked_candidates": [
                {
                    "ticker": t,
                    "trade_score": d.get("trade_score", 0),
                    "invest_score": d.get("invest_score", 0),
                    "signal_count": d.get("signal_count", 0),
                    "signal_sources": d.get("signal_sources", []),
                }
                for t, d in ranked[:15]
            ],
            "enriched_data": {t: d for t, d in ranked[:12]},
            # Market structure
            "market_movers": movers,
            "fear_greed": fear_greed,
            "fred_macro": fred_macro,
            "fmp_market_data": fmp_data,
            # Category highlights (top 3 from each screener)
            "highlights": {
                "stage2_breakouts": stage2_breakouts[:3] if isinstance(stage2_breakouts, list) else [],
                "volume_breakouts": volume_breakouts[:3] if isinstance(volume_breakouts, list) else [],
                "macd_crossovers": macd_crossovers[:3] if isinstance(macd_crossovers, list) else [],
                "high_short_float": high_short[:3] if isinstance(high_short, list) else [],
                "insider_buying": insider_buying[:3] if isinstance(insider_buying, list) else [],
                "revenue_growth": revenue_leaders[:3] if isinstance(revenue_leaders, list) else [],
                "rsi_recovery": rsi_recovery[:3] if isinstance(rsi_recovery, list) else [],
                "social_trending": [t.get("ticker") for t in trending[:5]] if isinstance(trending, list) else [],
            },
            "market_news": market_news[:8] if isinstance(market_news, list) else [],
            "upcoming_earnings": upcoming_earnings[:5] if isinstance(upcoming_earnings, list) else [],
        }PART 2: Add Briefing RouteIn agent/claude_agent.py, find the _gather_data method. Add this block after the existing elif blocks:python        elif category == "briefing":
            return await self.data.get_morning_briefing()PART 3: Add to ClassifierIn agent/prompts.py, in the QUERY_CLASSIFIER_PROMPT, add this line:- "briefing": User asks for a morning briefing, daily overview, "what should I do today", "top moves today", "daily snapshot", "what's the play today", "quick overview", or clicks the daily briefing button. This is a combined intelligence report, not a single category scan.PART 4: Add Briefing Display Format to System PromptIn agent/prompts.py, add this format definition BEFORE the ### FORMAT 7: "chat" section:### FORMAT: "briefing" — Daily Intelligence Briefing
Use when: user asks for a morning briefing, daily overview, "what should I do today", combined snapshot.

This is your MOST IMPORTANT format. It combines all data sources into one actionable briefing.
The user wants to spend 60 seconds reading this and know exactly what to do.

Structure your analysis in this order:
1. Market Pulse (2-3 sentences): Risk-on or risk-off? Bull or bear? One-line verdict.
2. Key Numbers: SPY, QQQ, VIX, Fear & Greed, DXY, 10Y yield, oil — just the numbers and direction arrows.
3. What's Moving: The 3-4 most notable things happening right now across all data.
4. Top Moves: Your 3-5 highest conviction actionable trades for today/this week.
```json{
"display_type": "briefing",
"market_pulse": {
"verdict": "Cautiously Bullish",
"summary": "Risk-on with caveats. SPY holding above 20 SMA, breadth improving, but VIX elevated and CPI in 2 days could shift everything. Favor long setups with tight stops.",
"regime": "Risk-On"
},
"key_numbers": {
"spy": {"price": "$520.30", "change": "+0.8%", "trend": "↑ Above all SMAs"},
"qqq": {"price": "$445.10", "change": "+1.1%", "trend": "↑ Leading"},
"iwm": {"price": "$198.50", "change": "+0.3%", "trend": "→ Lagging"},
"vix": {"price": "18.5", "change": "-5%", "trend": "↓ Declining (bullish)"},
"fear_greed": {"value": "42", "label": "Fear", "trend": "↑ Recovering from 35"},
"dxy": {"price": "103.5", "change": "-0.4%", "trend": "↓ Weakening (bullish for commodities)"},
"ten_year": {"price": "4.25%", "change": "+2bps", "trend": "→ Range-bound"},
"oil": {"price": "$78.50", "change": "+1.2%", "trend": "↑ Bouncing off support"},
"gold": {"price": "$2,420", "change": "+0.6%", "trend": "↑↑ New ATH"}
},
"whats_moving": [
{"headline": "AI stocks leading — NVDA +3%, CRDO +8% on volume", "category": "Sector Momentum"},
{"headline": "Uranium breakout — CCJ above 200 SMA for first time in 3 months on 2.5x volume", "category": "Stage 2 Breakout"},
{"headline": "Short squeeze building in SMR — 28% short float, social mentions +400%", "category": "Squeeze Alert"},
{"headline": "CPI data Wednesday — market positioning defensively, VIX options activity elevated", "category": "Upcoming Catalyst"}
],
"signal_highlights": {
"best_ta_setup": {"ticker": "CRDO", "signal": "Stage 2 breakout on 3x volume, MACD crossover, RSI 58"},
"best_fundamental": {"ticker": "TMDX", "signal": "Revenue +45% YoY, EBITDA turned positive, insider bought $2M"},
"hottest_social": {"ticker": "SMR", "signal": "StockTwits #2 trending, 82% bullish, mentions +400% 24hr"},
"top_squeeze": {"ticker": "MARA", "signal": "32% short float, 3.2x volume, breaking above 50 SMA"},
"biggest_volume": {"ticker": "IONQ", "signal": "5.8x avg volume, up 12%, quantum computing catalyst"},
"strongest_sector": {"sector": "Semiconductors (SMH)", "signal": "+2.1% today, RSI 61, outperforming SPY by 8% monthly"}
},
"top_moves": [
{
"rank": 1,
"ticker": "CRDO",
"action": "BUY",
"conviction": "High",
"thesis": "Stage 2 breakout from 4-month base. 3x volume confirms institutional buying. MACD just crossed bullish. AI connectivity play with NVDA as customer. Revenue +60% YoY.",
"signals_stacking": ["stage2_breakout", "volume_breakout", "macd_crossover", "revenue_growth"],
"signal_count": 4,
"entry": "$62-$64",
"stop": "$58 (below breakout level)",
"target": "$75 (measured move from base)",
"risk_reward": "1:3.2",
"timeframe": "2-4 weeks"
},
{
"rank": 2,
"ticker": "CCJ",
"action": "BUY",
"conviction": "High",
"thesis": "Uranium sector breakout. CCJ clearing 200 SMA on 2.5x volume. Nuclear renaissance theme with policy tailwinds. Revenue +28% YoY, expanding margins.",
"signals_stacking": ["stage2_breakout", "volume_breakout", "accumulation"],
"signal_count": 3,
"entry": "$52-$54",
"stop": "$48 (below 200 SMA)",
"target": "$65 (prior high)",
"risk_reward": "1:2.8",
"timeframe": "1-3 months"
}
],
"upcoming_catalysts": [
"CPI Release — Wed Feb 12 (consensus 3.1%, market-moving)",
"NVDA Earnings — Feb 26 (AI bellwether)",
"FOMC Minutes — Wed Feb 19"
],
"portfolio_bias": "Lean long with tight stops. Favor Stage 2 breakouts in AI and uranium. Keep 10-15% cash for CPI volatility. Avoid chasing extended names."
}

RULES FOR BRIEFING FORMAT:
- market_pulse MUST give a one-word verdict (Bullish, Cautiously Bullish, Neutral, Cautiously Bearish, Bearish) and a regime label (Risk-On, Risk-Off, Transitioning)
- key_numbers MUST include all 9 metrics with price, change, and trend arrow
- whats_moving should be 3-5 items, each with a category label
- signal_highlights MUST have one pick from each category: best_ta_setup, best_fundamental, hottest_social, top_squeeze, biggest_volume, strongest_sector
- top_moves is the MOST IMPORTANT section. 3-5 picks maximum. Each MUST have:
  - signals_stacking: list of which screeners this ticker appeared in
  - signal_count: how many screeners (higher = stronger signal)
  - Full trade plan: entry, stop, target, risk/reward, timeframe
- Picks with 3+ signals stacking should be ranked higher than picks with 1-2 signals
- upcoming_catalysts: 2-4 events in next 7 days that could move markets
- portfolio_bias: one paragraph telling the user how to position overall
- This format should feel like a hedge fund morning note, not a data dumpRe-publish/deploy the backend.