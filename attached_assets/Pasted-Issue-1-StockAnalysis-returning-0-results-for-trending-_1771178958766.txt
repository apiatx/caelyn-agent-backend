Issue 1: StockAnalysis returning 0 results for trending
The StockAnalysis scraper I wrote targets /markets/active/ and /markets/gainers/ — but those pages are JavaScript-rendered, so BeautifulSoup likely gets empty HTML. The scraper is silently returning nothing.
Give this to your backend Replit Agent:

StockAnalysis trending scraper is returning 0 results. The pages at stockanalysis.com/markets/active/ and stockanalysis.com/markets/gainers/ are JavaScript-rendered so BeautifulSoup gets empty HTML. Please fix by trying one of these approaches:
Option A (preferred): Check if StockAnalysis has any JSON/API endpoints behind their pages. Open the browser dev tools Network tab on https://stockanalysis.com/markets/active/ and look for XHR/fetch requests that return JSON data. StockAnalysis likely loads data from an internal API like https://stockanalysis.com/api/markets/active or similar. If you find a JSON endpoint, use that directly instead of scraping HTML.
Option B: If no API endpoint exists, use the existing StockAnalysis provider to get trending data differently. Instead of scraping the trending page, query Finviz for today's most active tickers and then cross-reference by fetching StockAnalysis overview data for each of those tickers. We're already doing this in enrichment — we just need to also count StockAnalysis as a "source" if the ticker has data there.
Option C: Try fetching with headers that request the server-rendered version. Some sites serve static HTML to certain user agents. Try adding Accept: text/html and a Googlebot user agent to see if the server returns pre-rendered content.
Whichever approach works, make sure the function returns a list of dicts with at minimum: ticker, company, source: "stockanalysis"
Also check why Polygon is returning 0 results for market movers (gainers/losers). The get_market_movers method may be using a paid-tier endpoint. If so, replace it with the free-tier approach — get the top gainers by fetching daily bars for SPY components and sorting by % change, or simply skip Polygon movers and rely on the other 5 sources.

Issue 2: Response formatting is ugly — too much spacing, # headers, hard to read
This is a Claude output formatting problem controlled by the system prompt. The agent is outputting raw markdown with # headers instead of structured JSON that your frontend renders into styled cards.
Give this to your backend Replit Agent:

URGENT: The agent responses are outputting raw markdown text with # headers and excessive spacing instead of structured JSON. This is happening because Claude is ignoring the display_type format instructions and falling back to freeform markdown. Please make these changes:
1. Update the system prompt to be MUCH stricter about JSON output
In agent/prompts.py, find the main system prompt and add this at the VERY TOP, before any other instructions:
CRITICAL OUTPUT RULE — READ THIS FIRST:
You MUST respond with a valid JSON object for EVERY query. No exceptions.
Do NOT use markdown headers (#, ##, ###).
Do NOT use horizontal rules (---).
Do NOT output freeform text paragraphs outside of JSON string values.
Do NOT add spacing between sections with blank lines.

Your ENTIRE response must be a single JSON object starting with { and ending with }.
The display_type field determines the format. Follow the exact schema for each display_type.

If you write ANYTHING outside the JSON object, the frontend will break.
2. Add formatting rules INSIDE each display_type format section
For the "trending" format specifically, add these rules:
FORMATTING RULES FOR ALL display_type RESPONSES:
- Every field value that contains analysis text should be CONCISE — 1-3 sentences max, not paragraphs
- The "thesis" or "why_trending" field: 2-3 sentences maximum
- The "risk" field: 1-2 sentences maximum  
- The "ta_summary" field: Single line, pipe-separated like "RSI 62 | Above SMA20 ✓ | Below SMA50 ✗ | MACD bullish"
- The "fundamental_snapshot" field: Single line like "Rev $1.47B (+12% YoY) | Net Inc -$12.5M | Fwd P/E 9.7x | 52% insider owned"
- The "sentiment" field: Single line like "92% bullish on StockTwits (23K watchers) | Not on Yahoo trending"
- NEVER use # or ## or ### markdown headers inside JSON string values
- NEVER use --- horizontal rules inside JSON values
- NEVER use bullet points (- or *) inside JSON string values — use pipe separators or commas instead
- Keep ALL text fields TIGHT and DENSE — this is a trading terminal, not a blog post
3. For the trending format specifically, make sure the JSON structure matches what the frontend renderer expects
The frontend renderTrades function expects trending_tickers array with these fields per ticker:
ticker, company, price, change, market_cap, quant_score, conviction,
thesis (short), ta_summary (one line), risk (short),
sentiment (one line), fundamental_snapshot (one line),
sources (array), source_count (number), why_trending (2-3 sentences),
trade_plan: { entry, stop, target_1, target_2, risk_reward }
If Claude outputs anything OTHER than this JSON structure, the frontend falls back to rendering raw text — which is what's happening now. The response must be parseable JSON.
4. Add a response validation step
In agent/claude_agent.py, after receiving Claude's response, add a check:
python# After getting Claude's response text
response_text = response_text.strip()

# If response doesn't start with {, try to extract JSON from it
if not response_text.startswith('{'):
    # Try to find JSON in the response
    import re
    json_match = re.search(r'\{[\s\S]*\}', response_text)
    if json_match:
        response_text = json_match.group(0)
    else:
        # Claude didn't output JSON — wrap the raw text as a chat response
        import json
        response_text = json.dumps({
            "display_type": "chat",
            "message": response_text
        })
This ensures the frontend ALWAYS receives JSON, even if Claude goes off-script.
Re-deploy after all changes.