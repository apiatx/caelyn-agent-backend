As I suspected — my project snapshot is from before Phase 2. But I can still diagnose the issue from the error behavior and the code structure. The error Error: [object Object] on cross_asset_trending means one of two things:

The compression layer is stripping fields that the cross_asset_trending post-processing or Claude contract needs, causing Claude to return malformed JSON
The compression is returning an error dict instead of data, and the frontend can't render {"error": "..."} as a string

The most likely culprit: the _compress_trending function in Phase 2 is catching cross_asset_trending category data but the cross_asset_trending data structure is very different from regular trending data. Cross-asset data has grok_shortlist, equities buckets, crypto arrays, commodities, social_signal, edgar, etc. — the generic trending compressor likely strips or mishandles these.
Here are the exact Replit Agent instructions to fix it:

Prompt for Replit Agent:
## Bug Fix: "Trending Now" (cross_asset_trending) returns "Error: [object Object]"

### Problem
After Phase 2 (data compression layer), the "Trending Now" preset returns an error to the frontend. The error appears as "Error: [object Object]" which means the backend is returning an error object that the frontend can't render.

### Root Cause
The `compress_for_claude()` function in `data_compressor.py` routes `cross_asset_trending` to `_compress_trending()`, but cross_asset_trending data has a VERY different structure from regular trending data. Cross-asset data contains:
- `grok_shortlist` (with nested `equities.large_caps`, `equities.mid_caps`, `equities.small_micro_caps`, `crypto`, `commodities`)
- `grok_available` flag
- `social_signal` 
- `edgar` enrichment data
- `light_enrichment`
- `module_status`
- `social_scan_unavailable` / `social_scan_notice`
- `cross_asset_debug`
- Stock/crypto/commodity trending data from market scanners

The generic `_compress_trending` function likely strips or corrupts fields that either Claude needs to generate valid output, or that the post-processing in `handle_query()` needs.

There may also be a second issue: if the compression itself throws an exception (e.g., on an unexpected data shape), the fallback `except` block might not be working correctly, or the error propagates in a way the frontend can't render.

### Fix: Three things to do

#### 1. Add a dedicated cross_asset_trending compressor in `data_compressor.py`

In the `compress_for_claude()` function's compressors dict, add a separate entry:
```python
    compressors = {
        "best_trades": _compress_best_trades,
        "briefing": _compress_briefing,
        "cross_asset_trending": _compress_cross_asset_trending,  # ADD THIS - separate from trending
        "trending": _compress_trending,
        "cross_market": _compress_trending,
        "deterministic_screener": _compress_screener,
        "crypto": _compress_crypto,
        "sector_rotation": _compress_sector,
        "macro_outlook": _compress_macro,
    }
```

Then add the new compressor function:
```python
def _compress_cross_asset_trending(data: dict) -> dict:
    """
    Cross-asset trending has a unique structure with Grok shortlist, 
    multi-asset buckets, social signals, and EDGAR data.
    Must preserve all fields that Claude and post-processing need.
    Only strip: raw debug internals, oversized nested data.
    """
    # This data structure is complex and the post-processing / Claude contract
    # depends on many fields. Be CONSERVATIVE — only strip known-safe fields.
    compressed = {}
    
    # Pass through all top-level fields, only compressing known-large ones
    for key, value in data.items():
        # Skip internal debug that Claude doesn't need
        if key in ("cross_asset_debug", "_cross_asset_debug"):
            continue
        
        # Trim Grok shortlist — keep structure but limit items per bucket
        if key == "grok_shortlist" and isinstance(value, dict):
            trimmed_grok = {}
            for gk, gv in value.items():
                if gk == "equities" and isinstance(gv, dict):
                    trimmed_eq = {}
                    for bucket_name, bucket_items in gv.items():
                        if isinstance(bucket_items, list):
                            trimmed_eq[bucket_name] = bucket_items[:8]
                        else:
                            trimmed_eq[bucket_name] = bucket_items
                    trimmed_grok[gk] = trimmed_eq
                elif isinstance(gv, list):
                    trimmed_grok[gk] = gv[:10]
                else:
                    trimmed_grok[gk] = gv
            compressed[key] = trimmed_grok
            continue
        
        # Trim stock_trending enriched_data — keep top entries only
        if key == "stock_trending" and isinstance(value, dict):
            trimmed_stock = dict(value)
            enriched = trimmed_stock.get("enriched_data", {})
            if isinstance(enriched, dict) and len(enriched) > 10:
                top_keys = list(enriched.keys())[:10]
                trimmed_stock["enriched_data"] = {k: enriched[k] for k in top_keys}
            compressed[key] = trimmed_stock
            continue
        
        # Trim news to headlines only
        if key == "news_context" and isinstance(value, dict):
            compressed[key] = _trim_news(value)
            continue
        
        # Everything else passes through — including social_signal, edgar, 
        # module_status, grok_available, light_enrichment, etc.
        compressed[key] = value
    
    # Strip None values at top level only
    compressed = {k: v for k, v in compressed.items() if v is not None}
    
    return compressed
```

#### 2. Add safety logging in claude_agent.py compression block

Find the Phase 2 compression block in `handle_query()` (the section that calls `compress_for_claude`). Add better error handling and logging specifically for cross_asset_trending:
```python
        # Compress data before sending to Claude
        claude_data = market_data
        if market_data and isinstance(market_data, dict) and category != "followup":
            try:
                from data_compressor import compress_for_claude
                claude_data = compress_for_claude(market_data, category)
                compression = claude_data.get("_compression", {})
                print(f"[COMPRESS] {compression.get('raw_size', 0):,} → {compression.get('compressed_size', 0):,} chars "
                      f"({compression.get('ratio', 1)}x reduction) for category={category}")
            except Exception as e:
                print(f"[COMPRESS] Compression FAILED for category={category}, using raw data: {e}")
                import traceback
                traceback.print_exc()
                claude_data = market_data
```

Make sure the `except` block catches ALL exceptions and falls back to raw data. The `traceback.print_exc()` will show exactly what's failing if it happens again.

#### 3. Verify the _ask_claude function handles compressed data correctly

In `_ask_claude()` (around line 2726), the function calls `compress_data(market_data)` from the OLD data_compressor. This is a SECOND compression pass on top of the Phase 2 `compress_for_claude()`. This double-compression could be corrupting the data.

Check if `_ask_claude` is still calling `compress_data()` on the market_data it receives. If it is, it should NOT re-compress data that was already compressed by `compress_for_claude()`. Fix by checking for the `_compression` key:

Find this line in `_ask_claude` (around line 2738):
```python
            compressed = compress_data(market_data)
```

Replace with:
```python
            # Skip old compression if data was already compressed by compress_for_claude
            if market_data.get("_compression"):
                compressed = market_data
            else:
                compressed = compress_data(market_data)
```

### Testing

1. Click "Trending Now" — should render the cross-asset trending panel with tickers, not an error
2. Check server logs for `[COMPRESS]` line — should show category=cross_asset_trending
3. Check there is NO `[COMPRESS] Compression FAILED` line
4. Test Best Trades, Daily Briefing, and all 6 screener presets still work
5. Run `python -m pytest` — all tests must pass

### Success Criteria
- "Trending Now" renders correctly with cross-asset results
- No `Error: [object Object]` on any preset
- `[COMPRESS]` logs show reasonable compression ratios
- All other presets still work correctly
